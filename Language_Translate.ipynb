{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6CUzd925/q0oPWxwqkjQG"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJKV64FMH5rs",
        "outputId": "99a31089-b1e7-4466-a527-a73d18acd75e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "#Installing latest Hugging Face Transformers library\n",
        "!pip install git+https://github.com/huggingface/transformers/ -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Highlighting the version used\n",
        "!pip freeze | grep transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVtqui2oIw36",
        "outputId": "d4bb511a-b751-4b30-c695-94c09dc95f8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformers @ git+https://github.com/huggingface/transformers/@b7c381f01176b27013a44769b9a5b9b271613f07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast"
      ],
      "metadata": {
        "id": "DvVvD5-8OUf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Downloading the model and tokenizer\n",
        "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\")\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\", src_lang=\"en_XX\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqScoHTBO6rj",
        "outputId": "7798ab8e-9708-49b1-ee6f-7b112d5aa7b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Text to translate\n",
        "text_en = \"For the first time, Apple has reduced the launch prices of its top-end iPhones\""
      ],
      "metadata": {
        "id": "h2gCw_AqPoiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Passing text on tokenizer and specifying Pytorch tensors\n",
        "model_inputs = tokenizer(text_en, return_tensors='pt')"
      ],
      "metadata": {
        "id": "w31EN0_ZR_ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Translation into Hindi\n",
        "generated_tokens_hi = model.generate(\n",
        "    **model_inputs,\n",
        "    forced_bos_token_id = tokenizer.lang_code_to_id[\"hi_IN\"]\n",
        ")"
      ],
      "metadata": {
        "id": "VUbhgIxjSf7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Translation into french\n",
        "generated_tokens_fr = model.generate(\n",
        "    **model_inputs,\n",
        "    forced_bos_token_id = tokenizer.lang_code_to_id[\"fr_XX\"]\n",
        ")"
      ],
      "metadata": {
        "id": "f9g97fTfUBJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Translation into Spanish\n",
        "generated_tokens_es = model.generate(\n",
        "    **model_inputs,\n",
        "    forced_bos_token_id = tokenizer.lang_code_to_id[\"es_XX\"]\n",
        ")"
      ],
      "metadata": {
        "id": "zmsyh8KusgGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translation_hi = tokenizer.batch_decode(generated_tokens_hi, skip_special_tokens=True)\n",
        "translation_fr = tokenizer.batch_decode(generated_tokens_fr, skip_special_tokens=True)\n",
        "translation_es = tokenizer.batch_decode(generated_tokens_es, skip_special_tokens=True)\n",
        "\n",
        "translations = {\n",
        "    \"Hindi\": translation_hi,\n",
        "    \"French\": translation_fr,\n",
        "    \"Spanish\": translation_es\n",
        "}"
      ],
      "metadata": {
        "id": "87heUawBTJJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YiBSGV0TfRn",
        "outputId": "c8c97b22-43f1-48e3-d96f-934611793891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Hindi': ['पहली बार, एप्पल ने अपने शीर्षस्थ iPhones के शुरुआती मूल्यों को कम किया है'],\n",
              " 'French': ['Pour la première fois, Apple a réduit les prix de lancement de ses iPhones haut de gamme'],\n",
              " 'Spanish': ['Por primera vez, Apple ha reducido los precios de lanzamiento de sus iPhones de top-end']}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}